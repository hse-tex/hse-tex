\subsection{Многомерное нормальное распределение. Свойства нормального вектора: линейный образ нормального распределения нормален, характеризация через одномерные распределения, значение параметров нормального вектора, равносильность независимости и некоррелированности компонент. Представление нормального вектора, как линейный образ стандартного нормального вектора, ортогонализация. Плотность нормального вектора.}
\textbf{Определение} Случайный вектор X имеет нормальное распределение или явялется гауссовским, если $\phi_x(y) = E[exp(i<X, y>)] = e^{-\frac{1}{2}<Ry, y> + i<a, y>}$.\\
Где $a = (a_1, ..., a_m) \in R^m, R -$ симметричная неотрицательно определенная $m\times m$ матрица. Далее пишем $X \sim N(a, R)$.\\
\subsubsection{Свойства нормального вектора: линейный образ нормального распределения нормален, характеризация через одномерные распределения, значение параметров нормального вектора, равносильность независимости и некоррелированности компонент.}
\textbf{Предложение 1.} $X\sim N(a, R)$, то вектор $AX + b\sim N(Aa + b, ARA^*)$\\
\textit{Доказательство.} Доказывается простой подстановкой по определению:\\
$\phi_{AX + b}(y) =  E[exp(i<AX + b, y>)] = e^{i<b, y>}E[exp(i<X, A^*y>)] = e^{i<b, y> + i<a, A^*y> - \frac{1}{2}(RA^*y, A^*y)}$\\
Остается заметить, что $<RA^*y, A^*y> = <ARA^*y, y>$, а также $i<b, y> + i<a, A^*y>  = i<Aa + b, y>$.\\
\\
\textbf{Теорема 1.} Вектор Х имеет нормальное распределение тогда и только тогда, когда для каждого вектора y случайная величина $<y, X>$ имеет нормальное распределение.\\
\textit{Доказательство.} Так как по условию $X \sim N(a, R)$, то:\\
$$\phi_{<X, y>}(t) = E[exp(it<X, y>)] = e^{-\frac{1}{2}t^2<Ry, y> + it<a, y>}$$
Иными словами, $<X, y> \sim N(<a, y>, <Ry, y>$, поскольку $<a, y> = E[<X, y>], <Ry, y> = D[<X, y>]$.\\
Докажем обратно:\\
$$\phi_{X}(y) = Ee^{i<X, y>} = \phi_{<X, y>}(1) = e^{-\frac{1}{2}D[<X, y>] + e[<X, y>]} = e^{-\frac{1}{2}t^2<Ry, y> + it<a, y>}$$
Не забываем, что R - ковариационная матрица X, а - вектор средних.\\
\\
\textbf{Следствие 1.} Если $X \sim N(a, R)$, то R - ковариационная матрица X, а - вектор средних.\\
\\
\textbf{Следствие 2.} Если вектор $(X_1, X_2)$ имеет нормальное распределение и $cov(X_1, X_2) = 0$, то величины $X_1$ и $X_2$ независимы.\\
\textit{Доказательство} Если ковариация равна 0, то у нас независимость дисперсий:\\
$$\phi_{(X_1, X_2)}(y_1, y_2) = e^{-\frac{1}{2}(y_1^2DX_1 + y_2^2DX_2 + i(y_1EX_1 + y_2EX_2)} = \phi_{X_1}(y_1)\phi_{X_2}(y_2)$$

\subsubsection{Представление нормального вектора, как линейный образ стандартного нормального вектора, ортогонализация}
\textbf{Следствие 3.} Если X $\sim$ N (a, R), то найдется такая матрица A, что X = AZ + a, где
$Z = (Z_1, ..., Z_k)$ и случайные величины Zj независимы и имеют стандартное нормальное распределение, $AA^* = R$.\\
\textit{Доказательство.} Перейдем к случайным векторам $X_j' = X_j - a_j$. Нам надо найти ортонормированный базис в линейном пространстве $span(X_1', ..., X_m')$ со скалярным произведением $(X, Y) = E[XY]$. Для этого будем использовать метод Грамма-Шмидта. После него мы получаем случайные величины $(Z_1, ..., Z_k) = Z$, что линейно выражаются через $X_1', ... X_m'$. Т.е. в частности вектор Z - нормальный и $E[Z_j] = 0$, кроме того система является ортонормированным базисом в $span(X_1', ..., X_m')$. То, что это базис означает X = AZ. Ортономированность означает $cov(Z_k, Z_j) = E[Z_k, Z_j) = 0, D[Z_j] = E[Z_j^2] = 1$. Поэтому случайные величины $Z_j \sim N(0, 1)$ и независимы. Равенство $AA^* = R$ следует из того, как меняется матрица при линейных отображениях.
\\
\subsubsection{Плотность нормального вектора.}
\textbf{Теорема 2.} Если $X\sim N(a, R)$ и $detR \neq 0$, то случайны вектор X имеет плотность:\\
$$\rho(x) = \frac{1}{(2\pi)^{\frac{m}{2}} \sqrt{detR}}e^{-\frac{1}{2}<R^{-1}(x - a), x - a>}$$
\textit{Доказательство.} Поскольку можем представить Х как $AZ + a$, где A матрица квадртная и невырожденная(иначе R = $AA^*$ вырождена), то:\\
$P(X \in B) = P(AZ + a \in B) = \frac{1}{(\pi)^{\frac{m}{2}}}\int_{Ax + a \in B} e^{-\frac{1}{2}|x|^2}dx = \frac{1}{(\pi)^{\frac{m}{2}}detA}\int_{B} e^{-\frac{1}{2}|A^{-1}(y - a)|^2}dy$\\
Осталось заметить, что $|A^{-1}(y - a)|^2 = <A^{-1}(y - a), A^{-1}(y - a)> = <(AA)^{-1}(y - a), (y - a)>$ и $(detA)^2 = detR$.
